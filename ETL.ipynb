{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Proyecto Individual ML Ops STEAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo las librerias que considero necesarias para hacer la extración de los Data Set\n",
    "import json\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas de ubicación para los datasets:\n",
    "ruta_reviews = 'E:\\\\AAADATOS\\Henry\\\\AA_Data_Science\\\\MATERIAL_PI\\\\DATA_PI MLOps - STEAM\\\\Data_sets\\\\australian_user_reviews.json'\n",
    "ruta_items = 'E:\\\\AAADATOS\\Henry\\\\AA_Data_Science\\\\MATERIAL_PI\\\\DATA_PI MLOps - STEAM\\\\Data_sets\\\\australian_users_items.json'\n",
    "ruta_games = 'E:\\\\AAADATOS\\Henry\\\\AA_Data_Science\\\\MATERIAL_PI\\\\DATA_PI MLOps - STEAM\\\\Data_sets\\\\output_steam_games.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set australian_user_reviews.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se inicializa una lista vacia donde alamcenare los datos del archivo .JSON\n",
    "filas = []\n",
    "# Se abre el archivo .JSON con el modulo 'with'\n",
    "with open(ruta_reviews, 'r', encoding='utf-8') as archivo:\n",
    "    for line in archivo.readlines():\n",
    "        filas.append(ast.literal_eval(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se inicializa el primer DataFrame a partir de la lista donde se extrajo el archivo .JSON\n",
    "df_reviews = pd.DataFrame(filas)\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se evidencia que la columna \"reviews\" contiene listas como dato así que se tiene que proceder a expandirla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = df_reviews.explode('reviews').reset_index() # Se redefine el DatFrame con una descomposición del campo para desanidarla y se reinicia el conteo del índice\n",
    "df_reviews = df_reviews.drop(columns='index') # Se elimina el campo 'index'\n",
    "df_reviews = pd.concat([df_reviews, pd.json_normalize(df_reviews['reviews'])], axis=1) # Se normalizan los datos JSON de la columna 'reviews' aplanando los datos, convirtiendolos en un formato tabular y concatenando de manera horizontal el DatFrame original con el del contendio de 'reviews' \n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se empieza a analizar y transformar los datos del DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información general del DataFrame\n",
    "df_reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NULOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conteo de Nulos\n",
    "nulos = df_reviews.isna().sum()\n",
    "nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar los valores Nulos\n",
    "df_nulos = df_reviews[df_reviews.isnull().any(axis=1)] # Se crea un nuevo DatFrame donde se filtra si hay algun valor nulo en la fila a partir del DataFrame orginal\n",
    "df_nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base al DataFrame anterior se puede afirmar que todos los Nulos corresponden estas filas donde no esta la información relevante para mis objetivos con las consignas que se me asignaron por lo cual se procedera a ser eliminados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimino las filas con valores nulos del DataFrame con el método 'dropna()'\n",
    "df_reviews.dropna(inplace=True)\n",
    "# Conteo de Nulos nuevamente para verificar\n",
    "nuevos_nulos = df_reviews.isna().sum()\n",
    "nuevos_nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta manera se han eliminado los valores Nulos del DataFrame hasta este punto de la transformación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se procede a evaluar el contenido de los campos y determinar su relevancia dentro de los obejtivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una variable que contiene los valores unicos del campo 'funny'\n",
    "valores_funny = df_reviews['funny'].unique() \n",
    "valores_funny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea otra variable para contar cuantos valores hay que no sean strings vacios (\"\")\n",
    "cant_funny = df_reviews[df_reviews['funny'] != ''].count()['funny']\n",
    "cant_funny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se hace una operación matematica para determinar que porcentaje representa los valores de funny completos dentro del conjunto del DataFrame\n",
    "total_filas_df = 59305\n",
    "print(f'La cantidad de valores que no son strings vacios en el campo \"funny\" representan un {round((cant_funny/total_filas_df)*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después del proceso anterior se puede determinar que los valores que se podrían considerar útiles del campo \"funny\" apenas representan un 13.74% dentro de todo el DataFrame por lo cual este campo en su conjunto se considerará presindible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una variable que contiene los valores unicos del campo 'last_edited'\n",
    "valores_last_edited = df_reviews['last_edited'].unique() \n",
    "valores_last_edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea otra variable para contar cuantos valores hay que no sean strings vacios (\"\")\n",
    "cant_last_edited = df_reviews[df_reviews['last_edited'] != ''].count()['last_edited']\n",
    "cant_last_edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se hace una operación matematica para determinar que porcentaje representa los valores de \"last_edited\" completos dentro del conjunto del DataFrame\n",
    "print(f'La cantidad de valores que no son strings vacios en el campo \"last_edited\" representan un {round((cant_last_edited/total_filas_df)*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después del proceso anterior se puede determinar que los valores que se podrían considerar útiles del campo \"last_edited\" apenas representan un 10.35% dentro de todo el DataFrame por lo cual este campo en su conjunto se considerará presindible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una variable que contiene los valores unicos del campo 'helpful'\n",
    "valores_helpful = df_reviews['helpful'].unique() \n",
    "valores_helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea otra variable para contar cuantos valores hay que no sean \"No ratings yet\"\n",
    "cant_helpful = df_reviews[df_reviews['helpful'] != 'No ratings yet'].count()['helpful']\n",
    "cant_helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se hace una operación matematica para determinar que porcentaje representa los valores de \"helpful\" completos dentro del conjunto del DataFrame\n",
    "print(f'La cantidad de valores que no son \"No ratings yet\" vacios en el campo \"helpful\" representan un {round((cant_helpful/total_filas_df)*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que se posee mas información sobre el campo \"helpful\" se puede determinar que es presindible no solo por que su información relevante represente un poco menos del 50%, sino también por que esta información 'útil' seria dificil de cuantificar y llevar a escala además en los requerimientos se indica que el campo mas relevante para el objetivo es \"review\" por lo cual este campo tambien se presindé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una variable que contiene los valores unicos del campo 'recommend'\n",
    "valores_recommend = df_reviews['recommend'].unique() \n",
    "valores_recommend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el proceso anterior se cerciora que el campo \"recommend\" contiene información relevante en todas las filas del DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se cambia el tipo de dato de la variable 'recommend'\n",
    "df_reviews['recommend'] = df_reviews['recommend'].astype(bool)\n",
    "df_reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se elimina la cadena 'Posted' de todos las filas del campo \"posted\"\n",
    "df_reviews['posted'] = df_reviews['posted'].str.replace('Posted', '')\n",
    "df_reviews.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea un nuevo campo llamado \"Date\" donde se almacenara el contenido de \"posted\" convertido a formato datetime\n",
    "df_reviews['Date'] = pd.to_datetime(df_reviews['posted'], dayfirst=True, errors='coerce') # Con estos atributos se logra primero que se reconozca adecuadamente el formato de la fecha en el campo \"posted\" y segundo que lo que no se reconozca como datetime se convierta en una NaT \"Not a Time\"\n",
    "df_reviews.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una variable para contabilizar la cantidad NaT's que hay en el nuevo campo \"Date\" del DataFrame\n",
    "cant_Not_Date = df_reviews['Date'].isna().sum()\n",
    "cant_Not_Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea un nuevo campor llamado \"Year\" donde se almacenara solamente el año de la review\n",
    "df_reviews['Year'] = pd.to_datetime(df_reviews['Date']).dt.year\n",
    "df_reviews.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que se cuenta con valores NaT en el campo \"Date\" el output del campo \"Year\" esta en formato float por lo cual se van a tranformar a formato \"int\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se cuenta la cantidad de frecuencia de valores unicos que posee el campo \"Year\"\n",
    "fecuencia_valores_Year = df_reviews['Year'].value_counts()\n",
    "fecuencia_valores_Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una variable para contabilizar la cantidad NaT's que hay en el nuevo campo \"Year\" del DataFrame\n",
    "cant_Not_Year = df_reviews['Year'].isna().sum()\n",
    "cant_Not_Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con las tranformaciones anteriores se puede establecer que la cantidad de filas donde faltan unicamente el año en el campo \"posted\" son 10119 y es por esta razón que hay nulos al momento de transformalos a formatos de fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se reemplaza los valores NaT del campo \"Year\" por el año 2016\n",
    "df_reviews['Year'].fillna(2016, inplace=True)\n",
    "cant_Not_Year = df_reviews['Year'].isna().sum() # Se vuelve a contar los valores Nulos del campo\n",
    "cant_Not_Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se cuenta la cantidad de frecuencia de valores unicos que posee el campo \"Year\" nuevamente\n",
    "fecuencia_valores_Year = df_reviews['Year'].value_counts()\n",
    "fecuencia_valores_Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta decisión se justifica en un análisis externo de sobre Steam en la cual se encuentra que las reviews que no llevan el año en la fecha de posteo es por que fueron realizadas en el año en curso de esta manera como el último año que se tenía registro en el campo \"posted\" era el \"2015\" se asume que el año en curso es el \"2016\" y este pasa a reemplazar los valores Nulos que se tenian en estos campos de fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se transforma los datos del campo \"Year\" de tipo float a tipo int\n",
    "df_reviews['Year'] = df_reviews['Year'].astype(int)\n",
    "df_reviews.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se elimina el punto '.' de todos las filas del campo \"posted\"\n",
    "df_reviews['posted'] = df_reviews['posted'].str.replace('.', '')\n",
    "df_reviews.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a modificar el campo \"posted\" para poder añadir el año \"2016\" donde no lo tiene y de esta manera poder completar todos los valores del campo \"Date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patron_4_digitos = r'(\\d{4})$' # Se crea una variable para identificar los valores donde no haya un patrón de cuatro dígitos consecutivos\n",
    "df_reviews.loc[~df_reviews['posted'].str.contains(patron_4_digitos, regex=True), 'posted'] += ', 2016' # Se crea una máscara booleana que es True para las filas donde no hay un patrón de 4 números consecutivos al final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso es hacer nuevamente el campo \"Date\" pero esta vez  se completaran todos los campos así no quedando valores Nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea elimina el anterior campo \"Date\" y se transforma nuevamente\n",
    "df_reviews = df_reviews.drop(columns='Date')\n",
    "df_reviews['Date'] = pd.to_datetime(df_reviews['posted'], dayfirst=True, errors='coerce') # Con estos atributos se logra primero que se reconozca adecuadamente el formato de la fecha en el campo \"posted\" y segundo que lo que no se reconozca como datetime se convierta en una NaT \"Not a Time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se nuevamente la variable para contabilizar la cantidad NaT's que hay en el nuevo campo \"Date\" del DataFrame\n",
    "cant_Not_Date = df_reviews['Date'].isna().sum()\n",
    "cant_Not_Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta vez ya no hay valores Nulos en los campos de fechas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminar campos no relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una lista con el nombre de los campos que se van a eliminar del DataFrame\n",
    "campos_out = ['user_url','reviews','funny','posted','last_edited','helpful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = df_reviews.drop(columns=campos_out)\n",
    "df_reviews.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto que ya se tienen los campos relevantes se procede a normalizar los nombre de estos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = df_reviews.rename(columns={'user_id': 'User_Id'})\n",
    "df_reviews = df_reviews.rename(columns={'item_id': 'Item_Id'})\n",
    "df_reviews = df_reviews.rename(columns={'recommend': 'Recommend'})\n",
    "df_reviews = df_reviews.rename(columns={'review': 'Review'})\n",
    "df_reviews.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se crea la columna 'sentiment_analysis' aplicando análisis de sentimiento con NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importa la libreria nltk y se descarga el lexicon 'vader_lexicon' necesario para realizar el análisis de sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea la función que analizara los valores de la columna \"Review\" para darles un valor númerico según el análisis de sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se inicializa el analizador de sentimientos \n",
    "AS = SentimentIntensityAnalyzer()\n",
    "\n",
    "# '0' si es malo \n",
    "# '1' si es neutral \n",
    "# '2' si es positivo\n",
    "\n",
    "# Funcion para asignar valores de acuerdo a la escala\n",
    "def puntaje_sentimiento(texto): # La variable de entrada de mi función seran los valores en formato str de la columna \"Review\"\n",
    "    if pd.isnull(texto) or texto == '': # Evalua si el valor es un Nulo o un string vacío\n",
    "        return 1 # Si es así retorna 1 que es un valor neutral\n",
    "    elif isinstance(texto, str): # Verifica que el \"texto\" se una instancia del tipo str\n",
    "        sentimiento = AS.polarity_scores(texto) # Se utiliza el analizador de sentimientos 'AS' para obtener un diccionario de puntajes de polarida y la función polarity_scores devuelve un diccionario que contiene puntajes para la polaridad positiva, negativa, neutra y un puntaje compuesto que resume la polaridad general del texto\n",
    "        puntaje_compuesto = sentimiento['compound'] # Se extrae el puntaje compuesto del diccionario de sentimientos\n",
    "        if puntaje_compuesto >= -0.05:\n",
    "            return 2 # es positivo\n",
    "        elif puntaje_compuesto <= -0.05:\n",
    "            return 0 # es malo\n",
    "        else:\n",
    "            return 1 # es neutral\n",
    "    else:\n",
    "        return 1 # Si no cumple ninguna condición es neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se convierte la columna 'Review' a formato str\n",
    "df_reviews['Review'] = df_reviews['Review'].astype(str)\n",
    "\n",
    "# Se aplica la función puntaje_sentimiento a la columna 'Review' creando una nueva columna llamada 'Sentiment_Analysis' que contendra los puntajes de este análisis\n",
    "df_reviews['Sentiment_Analysis'] = df_reviews['Review'].apply(puntaje_sentimiento)\n",
    "df_reviews.head(2)\n",
    "\n",
    "# Tardo 20.7 seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se verifica que los únicos valores del campo sean cadenas que coincidan con años\n",
    "fecuencia_valores_reviews = df_reviews['Sentiment_Analysis'].value_counts()\n",
    "fecuencia_valores_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este punto ya no es necesaria la columna \"Review\" y tal como se pide en las consignas esta ya cumplió su función y fue reemplazada por \"Sentiment_Analysis\" por lo caul va a ser eliminada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = df_reviews.drop(columns=['Review']) # Se elimina el campo 'Review'\n",
    "df_reviews.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se guarda el DataFrame en formatos mas ligeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews.to_csv('user_reviews.csv', index=False) # Se guarda el DataFrame en formato CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se convierte el archivo CSV a parquet bajo la compresión \"gzip\"\n",
    "ruta_csv_reviews = 'E:\\\\AAADATOS\\\\Henry\\\\AA_Data_Science\\\\MATERIAL_PI\\\\PI_ML_OPS_STEAM_DSFT17\\\\user_reviews.csv' # Se crea una variable con la ruta del archivo CSV\n",
    "df_reviews_temp = pd.read_csv(ruta_csv_reviews) # Se lee ese CSV en un nuevo DataFrame temporal para segurar como estan los datos\n",
    "df_reviews_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se guarada el DataFrame temporal en formato comprimido gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews_temp.to_csv('user_reviews.gzip', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se verifica que el archivo gzip comprimido pueda ser leido de manera efectiva y que no hayan problemas en los datos que este arroja\n",
    "df_reviews_parquet = pd.read_csv('user_reviews.gzip', compression='gzip')\n",
    "df_reviews_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews_parquet.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set australian_users_items.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se inicializa una lista vacia donde alamcenare los datso del archivo .JSON\n",
    "filas = []\n",
    "# Se abre el archivo .JSON con el modulo 'with'\n",
    "with open(ruta_items, 'r', encoding='utf-8') as archivo:\n",
    "    for line in archivo.readlines():\n",
    "        filas.append(ast.literal_eval(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se inicializa el DataFrame a partir de la lista donde se extrajo el archivo .JSON\n",
    "df_items = pd.DataFrame(filas)\n",
    "df_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se evidencia que la columna \"items\" contiene listas como dato así que se tiene que proceder a expandirla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items = df_items.explode('items').reset_index() # Se redefine el DatFrame con una descomposición del campo para desanidarla y se reinicia el conteo del índice\n",
    "df_items = df_items.drop(columns='index') # Se elimina el campo 'index'\n",
    "df_items = pd.concat([df_items, pd.json_normalize(df_items['items'])], axis=1) # Se normalizan los datos JSON de la columna 'reviews' aplanando los datos, convirtiendolos en un formato tabular y concatenando de manera horizontal el DatFrame original con el del contendio de 'reviews' \n",
    "df_items.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se empieza a analizar y transformar los datos del DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se verifica la información de los datos que contiene el DataFrame\n",
    "df_items.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NULOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conteo de Nulos\n",
    "nulos = df_items.isna().sum()\n",
    "nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se hace una operación matemática para determinar que poorcentaje de todo el DataSet representan esos valores Nulos\n",
    "total_filas_df = 5170015\n",
    "cant_nulos = 16806\n",
    "print(f'La cantidad de valores nulos en el total del DataFrame es de {round(((cant_nulos/total_filas_df)*100), 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gracias a la operación anterior se determina que la cantidad de datos Nulos en el conjunto total del DataFrame representa una cantidad muy infima de los datos por lo cual se decide a ser eliminados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se eliminan los valores Nulos\n",
    "df_items = df_items.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuevamente se ha un conteo de Nulos\n",
    "nulos = df_items.isna().sum()\n",
    "nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se verifica nuevamente la información del DataFrame\n",
    "df_items.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminar campos no relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se procede a eliminar campos no relevantes hasta este punto\n",
    "df_items.drop(['user_url','items','playtime_2weeks'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se considera el campo \"playtime_2weeks\" irrelevante ya que en las funciones que se especifican en la consigna solo piden las horas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items.shape # Se visualiza las dimensiones del DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido al tamaño del DataFrame se considera eliminar las filas cuyo valor en \"playtime_forever\" sea igual a 0 ya que esto significa que el juego no se jugó por lo cual no sería considerado para valorar cada juego lo cual también necesario para las consignas osea las horas igual a 0 convierte las filas en irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items = df_items[df_items['playtime_forever'] != 0.0] # Con este código reasigno el DatFrame sin las filas cuyos valores en 'playtime_forever' sea igual a 0.0 horas\n",
    "df_items.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se hace una operación para determinar en que porcentaje se redujo el tamaño del DataFrame\n",
    "print(f'El tamaño del DataFrame se redujo en un {100 - (round(((3285246/5153209)*100), 2))}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A traves de este [link](https://developer.valvesoftware.com/wiki/Steam_Web_API) se puede observar que se menciona lo siguiente \"playtime_forever The total number of minutes played \"on record\", since Steam began tracking total playtime in early 2009.\" por lo cual se intuye que este campo representa minutos pero ya que en las consignas se piden horas para las funciones de consulta se procede a tranformar a horas jugadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una función que convierte los minutos a horas y utilizando la función math.ceil(x) redondea hacia arriba el valor para tener valores enteros en horas\n",
    "import math\n",
    "\n",
    "def convertir_a_horas(aplicar):\n",
    "    # Función para convertir minutos a horas y redondear hacia arriba\n",
    "    \n",
    "    # Verificar si la columna ya está en formato float, si no, convertir\n",
    "    aplicar = aplicar.astype(float)\n",
    "    \n",
    "    # Convertir minutos a horas y redondear hacia arriba\n",
    "    horas = aplicar / 60\n",
    "    horas_redondeadas = horas.apply(lambda x: math.ceil(x))\n",
    "    \n",
    "    return horas_redondeadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items['playtime_forever'] = convertir_a_horas(df_items['playtime_forever'])\n",
    "df_items.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Se procede a cambiar el tipo de dato del campo \"item_id\" por tipo int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una variable que contiene los valores unicos del campo 'item_id' para evalular que solo contenga numeros\n",
    "valores_item_id = df_items['item_id'].unique() \n",
    "valores_item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora que se sabe que solo contiene valores númericos se procede a realizar el cambio de tipo de dato\n",
    "df_items['item_id'] = df_items['item_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items.info() # Se verifica que haya cambiado el tipo de dato del campo 'item_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto que ya se tienen los campos relevantes se procede a normalizar los nombre de estos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items = df_items.rename(columns={'user_id': 'User_Id'})\n",
    "df_items = df_items.rename(columns={'items_count': 'Items_Count'})\n",
    "df_items = df_items.rename(columns={'steam_id': 'Steam_Id'})\n",
    "df_items = df_items.rename(columns={'item_id': 'Item_Id'})\n",
    "df_items = df_items.rename(columns={'item_name': 'Item_Name'})\n",
    "df_items = df_items.rename(columns={'playtime_forever': 'Playtime_Forever_Hours'})\n",
    "df_items.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se guarda el DataFrame en formatos mas ligeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items.to_csv('user_items.csv', index=False) # Se guarda el DataFrame en formato CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se convierte el archivo CSV a parquet bajo la compresión \"gzip\"\n",
    "ruta_csv_items = 'E:\\\\AAADATOS\\\\Henry\\\\AA_Data_Science\\\\MATERIAL_PI\\\\PI_ML_OPS_STEAM_DSFT17\\\\user_items.csv' # Se crea una variable con la ruta del archivo CSV\n",
    "df_items_temp = pd.read_csv(ruta_csv_items) # Se lee ese CSV en un nuevo DataFrame temporal para segurar como estan los datos\n",
    "df_items_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se guarada el DataFrame temporal en formato comprimido gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items_temp.to_csv('user_items.gzip', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se verifica que el archivo gzip comprimido pueda ser leido de manera efectiva y que no hayan problemas en los datos que este arroja\n",
    "df_items_parquet = pd.read_csv('user_items.gzip', compression='gzip')\n",
    "df_items_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items_parquet.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set output_steam_games.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se inicializa una lista vacia donde alamcenare los datso del archivo .JSON\n",
    "filas = []\n",
    "# Se abre el archivo .JSON con el modulo 'with'\n",
    "with open(ruta_games, 'r', encoding='utf-8') as archivo:\n",
    "    for line in archivo.readlines():\n",
    "        filas.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se inicializa el DataFrame a partir de la lista donde se extrajo el archivo .JSON\n",
    "df_games = pd.DataFrame(filas)\n",
    "df_games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se empieza a analizar y transformar los datos del DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se verifica la información de los datos que contiene el DataFrame\n",
    "df_games.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminar campos no relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una lista con el nombre de los campos que se van a eliminar del DataFrame\n",
    "campos_eliminar = ['app_name','url','reviews_url','specs','price','early_access']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games = df_games.drop(columns=campos_eliminar)\n",
    "df_games.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Se decidio eliminar estos campos debido a diversas razones que van desde que tenian información poco relevante, información que se cumplia con la de otro campo o que no se considera necesaria para cumplir con las consignas que se piden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NULOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conteo de Nulos\n",
    "nulos = df_games.isna().sum()\n",
    "nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace notorio que hay filas que estan completamente llenas de NaN's así que se procedera a eliminar esas primero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games = df_games.dropna(how='all') # Se le indica que elimine solo las filas que contienen NaN en todos los campos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se vuelve a contar los Nulos\n",
    "nulos = df_games.isna().sum()\n",
    "nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se revisa el nuevo tamaño del DataFrame para ver en cuanto se redujo su contenido\n",
    "df_games.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Eliminando solamente las filas completas de valores Nulos se redujo el Data Set en un {100 - (round(((32134/120445)*100) ,2))}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se elimina la fila donde existe un valor Nulo en el campo \"id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games.dropna(subset=[\"id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Siguiendo las consignas de las funciónes de colsulta se puede determinar que los campos \"genres\" y \"developer\" son crusiales por lo cual se procedera a eliminar reemplazar sus datos con los campos que se consideran similares para darles una caracaterestica y las filas donde estos tengan valores Nulos en ambos campos serán eliminados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reemplazar_nulos_genres(df):\n",
    "    # Función para reemplazar valores nulos en 'genres' con valores de 'tags'\n",
    "    # y eliminar filas donde ambos son nulos\n",
    "    \n",
    "    # Verificar si hay valores no nulos en 'tags'\n",
    "    mask = df['tags'].notnull()\n",
    "    \n",
    "    # Reemplazar valores nulos en 'genres' con valores de 'tags'\n",
    "    df.loc[mask, 'genres'] = df.loc[mask, 'tags']\n",
    "    \n",
    "    # Eliminar filas donde tanto 'genres' como 'tags' son nulos\n",
    "    df.dropna(subset=['genres', 'tags'], how='all', inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games = reemplazar_nulos_genres(df_games) # Se ejecuta la función en el DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se vuelve a contar los Nulos\n",
    "nulos = df_games.isna().sum()\n",
    "nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reemplazar_nulos_developer(df):\n",
    "    # Función para reemplazar valores nulos en 'developer' con valores de 'tags'\n",
    "    # y eliminar filas donde ambos son nulos\n",
    "    \n",
    "    # Verificar si hay valores no nulos en 'publisher'\n",
    "    mask = df['publisher'].notnull()\n",
    "    \n",
    "    # Reemplazar valores nulos en 'developer' con valores de 'publisher'\n",
    "    df.loc[mask, 'developer'] = df.loc[mask, 'publisher']\n",
    "    \n",
    "    # Eliminar filas donde tanto 'developer' como 'publisher' son nulos\n",
    "    df.dropna(subset=['developer', 'publisher'], how='all', inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games = reemplazar_nulos_developer(df_games) # Se ejecuta la función en el DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se vuelve a contar los Nulos\n",
    "nulos = df_games.isna().sum()\n",
    "nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games.shape # Se analiza el número de filas que tiene el DataSet hasta el momento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a lo anterior se considera que la cantidad de valores Nulos del campo \"release_date\" son infimos dentro del conjunto del DataFrame por lo cual se procede a ser eliminados, es de aclarar que la información de este campo tambien es necesaria para las consginas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games.dropna(subset=[\"release_date\"], inplace=True) # Se eliminan los nulos del campo 'release_date'\n",
    "df_games.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se revisa cuantos valores nulos se tiene hasta el momento\n",
    "nulos = df_games.isna().sum()\n",
    "nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cantidad de Nulos que quedan en el campo \"publisher\" es considerable además de ser un campo que podría no ser presendible para las funciones se decide dejarlo y reemplazar los valores Nulos por un string que indique \"No Data\" de esta manera \"N/D\" y lo mismo para el campo \"tags\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games.info() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el tipo de dato de todos los campos esta en \"str\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se reemplaza los valores Nulos del campo 'tags' por una la siguiente lista '[N/D]'\n",
    "df_games['tags'] = df_games['tags'].fillna('[N/D]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se verifica que ya no hayan valores Nulos en el campo 'tags'\n",
    "nulos = df_games.isna().sum()\n",
    "nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se reemplaza los valores Nulos del campo 'publisher' por una el siguiente string 'N/D'\n",
    "df_games['publisher'] = df_games['publisher'].fillna('N/D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se verifica que ya no hayan valores Nulos en el campo 'publisher'\n",
    "nulos = df_games.isna().sum()\n",
    "nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta este punto ya no hay valores Nulos en el Data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Se identifica una complejidad en el campo \"release_date\" por lo cual se procede a ser tranformado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se realiza un filtrado de los valores que no coinciden con el patrón de fecha\n",
    "import re\n",
    "patron = re.compile(r'^\\d{4}-\\d{2}-\\d{2}$')\n",
    "filas_no_patron = df_games[~df_games['release_date'].astype(str).str.match(patron)]\n",
    "filas_no_patron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Se descubre que hay una cantidad de filas cuyos datos de \"release_date\" son muy variados pero se identifica un patrón en ellos haciendo posible que se pueda salvar algunas filas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea una función para extraer los últimos 4 digitos de los valores si los hay y los suma a un string para poder darle el formato que se necesita las fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_fecha(fecha_str):\n",
    "    # Función para convertir expresiones de fecha en formato de cadena a \"YYYY-MM-DD\"\n",
    "    \n",
    "    # Buscar los últimos cuatro dígitos en la cadena\n",
    "    ultimos_cuatro_digitos = ''.join(filter(str.isdigit, fecha_str))[-4:]\n",
    "    \n",
    "    # Concatenar con la cadena \"-01-01\"\n",
    "    fecha_resultante = ultimos_cuatro_digitos + \"-01-01\"\n",
    "    \n",
    "    return fecha_resultante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea un nuevo Data Frame para guardar el resultado de la función\n",
    "df_fechas_corregidas = pd.DataFrame()\n",
    "df_fechas_corregidas['release_date'] = filas_no_patron['release_date'].apply(convertir_fecha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fechas_corregidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se elimina las filas que no fueron transformadas de la manera deseada\n",
    "df_fechas_corregidas = df_fechas_corregidas[df_fechas_corregidas['release_date'] != \"-01-01\"]\n",
    "df_fechas_corregidas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aplican los cambios de las fechas corregidas al Data Frame orginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games.update(df_fechas_corregidas)\n",
    "df_games.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevamente se buscan las filas donde el campo \"release_date\" no coincida con el formato que se quiere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filas_no_patron = df_games[~df_games['release_date'].astype(str).str.match(patron)]\n",
    "filas_no_patron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se eliminan las filas que no coinciden con el patron de fecha de 'release_date'\n",
    "df_games = df_games.drop(filas_no_patron.index)\n",
    "df_games.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se verifica que no hayan valores mas largos como valor en'realease_rate' que no se puedan convertir a una fecha\n",
    "longitud_no_deseada = df_games[df_games['release_date'].astype(str).apply(len) != 10]\n",
    "longitud_no_deseada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se eliminan los últimos 6 dijitos del campo 'release_date' para que solamente quede los dijitos del año\n",
    "df_games['release_date'] = df_games['release_date'].astype(str).str[:4]\n",
    "df_games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se verifica que los únicos valores del campo sean cadenas que coincidan con años\n",
    "fecuencia_valores_date = df_games['release_date'].unique()\n",
    "fecuencia_valores_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se identifican unos valores que no coinciden con un año que puedieron aparecer al momento de rescatar algunas filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cantidad_valores_date = df_games['release_date'].value_counts()\n",
    "cantidad_valores_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se guaradan esos valores en una lista\n",
    "no_años = ['6441', '0181', '0111', '0174', '0171']\n",
    "\n",
    "# Se filtra por los valores que no coincidan con esa lista\n",
    "df_games = df_games[~df_games['release_date'].str[:4].isin(no_años)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se verifica nuevamente que los únicos valores del campo sean cadenas que coincidan con años\n",
    "fecuencia_valores_date = df_games['release_date'].unique()\n",
    "fecuencia_valores_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se reinicia el conteo del index del Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games = df_games.reset_index()\n",
    "df_games = df_games.drop(columns='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a Normalizar los nombres de los campos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games = df_games.rename(columns={'publisher': 'Publisher'})\n",
    "df_games = df_games.rename(columns={'genres': 'Genres'})\n",
    "df_games = df_games.rename(columns={'title': 'Title'})\n",
    "df_games = df_games.rename(columns={'release_date': 'Year'})\n",
    "df_games = df_games.rename(columns={'tags': 'Tags'})\n",
    "df_games = df_games.rename(columns={'id': 'Item_Id'})\n",
    "df_games = df_games.rename(columns={'developer': 'Developer'})\n",
    "df_games.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se transforma los tipos de datos de los valores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se cambia el tipo de dato del campo 'Release_Date' por tipo de dato Date Time\n",
    "df_games['Year'] = df_games['Year'].astype(int)\n",
    "df_games.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se transforma los datos del campo 'Item_Id' de tipo str a tipo int\n",
    "df_games['Item_Id'] = df_games['Item_Id'].astype(int)\n",
    "df_games.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se transforma los datos de los campos 'Genres' y 'Tags' de tipo str a tipo str\n",
    "df_games['Genres'] = df_games['Genres'].astype(str)\n",
    "df_games['Tags'] = df_games['Tags'].astype(str)\n",
    "df_games.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se verifica estos cambios de tipos de dato\n",
    "df_games.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se elimina los corchetes del principio y el final de las cadenas\n",
    "df_games['Genres'] = df_games['Genres'].str.strip('[]')\n",
    "df_games['Tags'] = df_games['Tags'].str.strip('[]')\n",
    "df_games.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se elimina la la comilla \"'\" de todos las filas de los campos  'Genres' y 'Tags'\n",
    "df_games['Genres'] = df_games['Genres'].str.replace(\"'\", '')\n",
    "df_games['Tags'] = df_games['Tags'].str.replace(\"'\", '')\n",
    "df_games.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una variable para contar cuantos valores hay que sean strings (\"\") en el campo 'Generes'\n",
    "cant_generes = df_games[df_games['Genres'] == ''].count()['Genres']\n",
    "cant_generes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una variable para contar cuantos valores hay que sean strings (\"\") en el campo 'Tags'\n",
    "cant_tags = df_games[df_games['Tags'] == ''].count()['Tags']\n",
    "cant_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta manera se verifica que ya no hay filas con datos irelevantes hasta el momento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Se decide tomar como relevante el contenido del campo \"Tags\" para las consultas sobre los generos por lo cual se unira al campo \"Genres\" creando un nuevo campo llamado \"Genres_Plus\" donde solo aparezcan los valores únicos resultantes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games['Genres_Plus'] = (df_games['Genres'].str.split(', ') + df_games['Tags'].str.split(', ')).apply(set).apply(list).apply(', '.join)\n",
    "df_games.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que se tiene el nuevo campo se procede a eliminar los originales y a normalizar el nuevo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se eliminan las columnas orginales\n",
    "df_games = df_games.drop(columns='Genres')\n",
    "df_games = df_games.drop(columns='Tags')\n",
    "df_games.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se le cambia el nombre al campo nuevo\n",
    "df_games = df_games.rename(columns={'Genres_Plus': 'Genres'})\n",
    "df_games.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que en algun punto se le asigo el valor \"[N/D]\" a los Nulos del campo \"tags\" ahora se puede proceder a ser eliminados ya que son innecesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se visualiza las filas donde existe ese valor en el campo 'Genres'\n",
    "df_filtrado = df_games[df_games['Genres'].str.contains('N/D')]\n",
    "df_filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se elimina el valor \"N/D\" de todos las filas del campo 'Genres\n",
    "df_games['Genres'] = df_games['Genres'].str.replace(\"N/D\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se verifica que el valor ya no exista en el campo 'Genres'\n",
    "df_filtrado = df_games[df_games['Genres'].str.contains('N/D')]\n",
    "df_filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para una mejor lectura del Data Frame se decide cambiar la posición del campo \"Publisher\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = list(df_games.columns)\n",
    "columnas[0], columnas[3] = columnas[3], columnas[0]\n",
    "df_games = df_games[columnas]\n",
    "df_games.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se guarda el DataFrame en formatos mas ligeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games.to_csv('user_games.csv', index=False) # Se guarda el DataFrame en formato CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se convierte el archivo CSV a parquet bajo la compresión \"gzip\"\n",
    "ruta_csv_items = 'E:\\\\AAADATOS\\\\Henry\\\\AA_Data_Science\\\\MATERIAL_PI\\\\PI_ML_OPS_STEAM_DSFT17\\\\user_games.csv' # Se crea una variable con la ruta del archivo CSV\n",
    "df_games_temp = pd.read_csv(ruta_csv_items) # Se lee ese CSV en un nuevo DataFrame temporal para segurar como estan los datos\n",
    "df_games_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se guarada el DataFrame temporal en formato comprimido gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games_temp.to_csv('user_games.gzip', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se verifica que el archivo gzip comprimido pueda ser leido de manera efectiva y que no hayan problemas en los datos que este arroja\n",
    "df_games_parquet = pd.read_csv('user_games.gzip', compression='gzip')\n",
    "df_games_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games_parquet.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
